{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputdir = \"../../data/website/databricks/hourly\"\n",
    "# outputdir = \"../../data/website/test/hourly\"\n",
    "\n",
    "# problematicpaths = []\n",
    "\n",
    "# for tt in [\"user\", \"spider\"]:\n",
    "#     for at in [\"desktop\", \"mobile-dev\", \"mobile-app\"]:\n",
    "#         for domain in [\"en.wikipedia\", \"de.wikipedia\", \"fr.wikipedia\", \"es.wikipedia\", \"ru.wikipedia\", \"zh.wikipedia\"]:\n",
    "#             for year in [2019]:\n",
    "#                 for month in [9]:\n",
    "#                     for day in range(1,32):\n",
    "\n",
    "#                         jsondic = {i:[] for i in range(24)}\n",
    "#                         filepathpattern = f\"./{inputdir}/{tt}/{at}/{domain}/{year}-{month:02d}-{day:02d}-*.csv\"\n",
    "#                         filepaths = glob.glob(filepathpattern)\n",
    "                        \n",
    "#                         if not filepaths:\n",
    "#                             print(f\"{filepathpattern} IS EMPTY\")\n",
    "#                             problematicpaths.append(filepathpattern)\n",
    "#                             continue\n",
    "\n",
    "#                         elif len(filepaths) != 24:\n",
    "#                             print(f\"{filepathpattern} DOES NOT CONTAIN 24 HOURS\")\n",
    "#                             problematicpaths.append(filepathpattern)\n",
    "#                             continue\n",
    "                        \n",
    "#                         for filepath in filepaths:\n",
    "#                             hour = int(filepath.split(\"-\")[-1].split(\".\")[0])\n",
    "#                             nested_csvs = glob.glob(filepath + \"/*.csv\")\n",
    "#                             if len(nested_csvs) != 1:\n",
    "#                                 print(f\"{filepathpattern} CONTAINS NOT EXACTLY 1 NESTED CSV\")\n",
    "#                                 break\n",
    "#                             realfilepath = nested_csvs[0]\n",
    "#                             with open(realfilepath, \"r\") as f:\n",
    "#                                 for line in f.read().split(\"\\n\"):\n",
    "#                                     x, y = line.split(\",\")\n",
    "#                                     jsondic[hour].append({\"x\":int(x), \"y\":int(y)})\n",
    "\n",
    "#                         outfilepath = f\"./{outputdir}/{tt}/{at}/{domain}/{year}-{month:02d}-{day:02d}.json\"\n",
    "#                         outfiledir = \"/\".join(outfilepath.split(\"/\")[:-1])\n",
    "\n",
    "#                         if not os.path.exists(outfiledir):\n",
    "#                             os.makedirs(outfiledir)\n",
    "\n",
    "#                         with open(outfilepath, \"w\") as f:\n",
    "#                             json.dump(jsondic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mdbfs:/mnt/group09/websitedata123/oct2019.parquet/_SUCCESS\u001b[0m -> ../../data/website/databricks/hourly2/oct2019.parquet/_SUCCESS\n",
      "\u001b[4mdbfs:/mnt/group09/websitedata123/oct2019.parquet/_committed_6403748976473738617\u001b[0m -> ../../data/website/databricks/hourly2/oct2019.parquet/_committed_6403748976473738617\n",
      "\u001b[4mdbfs:/mnt/group09/websitedata123/oct2019.parquet/_started_6403748976473738617\u001b[0m -> ../../data/website/databricks/hourly2/oct2019.parquet/_started_6403748976473738617\n",
      "\u001b[4mdbfs:/mnt/group09/websitedata123/oct2019.parquet/part-00000-tid-6403748976473738617-74b0a401-c1f1-48b1-80ff-40dee974c842-3083605-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/hourly2/oct2019.parquet/part-00000-tid-6403748976473738617-74b0a401-c1f1-48b1-80ff-40dee974c842-3083605-1.c000.snappy.parquet\n",
      "\u001b[4mdbfs:/mnt/group09/websitedata123/oct2019.parquet/part-00001-tid-6403748976473738617-74b0a401-c1f1-48b1-80ff-40dee974c842-3083597-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/hourly2/oct2019.parquet/part-00001-tid-6403748976473738617-74b0a401-c1f1-48b1-80ff-40dee974c842-3083597-1.c000.snappy.parquet\n",
      "\u001b[4mdbfs:/mnt/group09/websitedata123/oct2019.parquet/part-00002-tid-6403748976473738617-74b0a401-c1f1-48b1-80ff-40dee974c842-3083606-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/hourly2/oct2019.parquet/part-00002-tid-6403748976473738617-74b0a401-c1f1-48b1-80ff-40dee974c842-3083606-1.c000.snappy.parquet\n",
      "\u001b[4mdbfs:/mnt/group09/websitedata123/oct2019.parquet/part-00003-tid-6403748976473738617-74b0a401-c1f1-48b1-80ff-40dee974c842-3083596-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/hourly2/oct2019.parquet/part-00003-tid-6403748976473738617-74b0a401-c1f1-48b1-80ff-40dee974c842-3083596-1.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "# !dbfs cp -r \"dbfs:/mnt/group09/websitedata123/nice.parquet\" \"../../data/website/databricks/hourly2/sep2019.parquet\"\n",
    "# !dbfs cp -r \"dbfs:/mnt/group09/websitedata123/sep2018.parquet\" \"../../data/website/databricks/hourly2/sep2018.parquet\"\n",
    "# !dbfs cp -r \"dbfs:/mnt/group09/websitedata123/oct2019.parquet\" \"../../data/website/databricks/hourly2/oct2019.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>domain</th>\n",
       "      <th>trafficType</th>\n",
       "      <th>accessType</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1570525200</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>spider</td>\n",
       "      <td>desktop</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-08 09:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1570478400</td>\n",
       "      <td>de.wikipedia</td>\n",
       "      <td>spider</td>\n",
       "      <td>desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>2019-10-07 20:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1570471200</td>\n",
       "      <td>de.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>mobile-app</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>2019-10-07 18:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1570474800</td>\n",
       "      <td>de.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>mobile-app</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-07 19:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1570467600</td>\n",
       "      <td>de.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>desktop</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>2019-10-07 17:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188332</th>\n",
       "      <td>1570154400</td>\n",
       "      <td>ru.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>mobile-web</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-04 02:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188333</th>\n",
       "      <td>1570179600</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>desktop</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-04 09:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188334</th>\n",
       "      <td>1570136400</td>\n",
       "      <td>de.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>mobile-app</td>\n",
       "      <td>562</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-03 21:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188335</th>\n",
       "      <td>1570140000</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>mobile-web</td>\n",
       "      <td>13596</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-03 22:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188336</th>\n",
       "      <td>1570161600</td>\n",
       "      <td>de.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>mobile-web</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-04 04:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188337 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp        domain trafficType  accessType      y    x  \\\n",
       "0       1570525200  en.wikipedia      spider     desktop    125    1   \n",
       "1       1570478400  de.wikipedia      spider     desktop      2  121   \n",
       "2       1570471200  de.wikipedia        user  mobile-app     29    8   \n",
       "3       1570474800  de.wikipedia        user  mobile-app     58    2   \n",
       "4       1570467600  de.wikipedia        user     desktop      5   16   \n",
       "...            ...           ...         ...         ...    ...  ...   \n",
       "188332  1570154400  ru.wikipedia        user  mobile-web      9    1   \n",
       "188333  1570179600  en.wikipedia        user     desktop     36    4   \n",
       "188334  1570136400  de.wikipedia        user  mobile-app    562    1   \n",
       "188335  1570140000  en.wikipedia        user  mobile-web  13596    1   \n",
       "188336  1570161600  de.wikipedia        user  mobile-web     85    1   \n",
       "\n",
       "                      date  year  month  day  hour  \n",
       "0      2019-10-08 09:00:00  2019     10    8     9  \n",
       "1      2019-10-07 20:00:00  2019     10    7    20  \n",
       "2      2019-10-07 18:00:00  2019     10    7    18  \n",
       "3      2019-10-07 19:00:00  2019     10    7    19  \n",
       "4      2019-10-07 17:00:00  2019     10    7    17  \n",
       "...                    ...   ...    ...  ...   ...  \n",
       "188332 2019-10-04 02:00:00  2019     10    4     2  \n",
       "188333 2019-10-04 09:00:00  2019     10    4     9  \n",
       "188334 2019-10-03 21:00:00  2019     10    3    21  \n",
       "188335 2019-10-03 22:00:00  2019     10    3    22  \n",
       "188336 2019-10-04 04:00:00  2019     10    4     4  \n",
       "\n",
       "[188337 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../../data/website/databricks/hourly2/oct2019.parquet\").drop_duplicates()\n",
    "df[\"date\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "df[\"year\"] = df.date.dt.year\n",
    "df[\"month\"] = df.date.dt.month\n",
    "df[\"day\"] = df.date.dt.day\n",
    "df[\"hour\"] = df.date.dt.hour\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_json(df):\n",
    "    outputdir = \"../../data/website/hourly\"\n",
    "\n",
    "    jsondic = {i:[] for i in range(24)}\n",
    "\n",
    "    # for hour in range(24):\n",
    "    #     # cumx = 0\n",
    "    #     for _, (x, y) in df[df[\"hour\"]==hour][[\"x\", \"y\"]].iterrows():\n",
    "    #         # cumx += x\n",
    "    #         jsondic[hour].append({\"x\":int(cumx), \"y\":int(y)})\n",
    "\n",
    "    for _, (hour, x, y) in df[[\"hour\", \"x\", \"y\"]].iterrows():\n",
    "        jsondic[hour].append({\"x\":int(x), \"y\":int(y)})\n",
    "\n",
    "    tt = df[\"trafficType\"].iloc[0]\n",
    "    at = df[\"accessType\"].iloc[0]\n",
    "    domain = df[\"domain\"].iloc[0]\n",
    "    year = df[\"year\"].iloc[0]\n",
    "    month = df[\"month\"].iloc[0]\n",
    "    day = df[\"day\"].iloc[0]\n",
    "\n",
    "    outfilepath = f\"./{outputdir}/{tt}/{at}/{domain}/{year}-{month:02d}-{day:02d}.json\"\n",
    "    outfiledir = \"/\".join(outfilepath.split(\"/\")[:-1])\n",
    "\n",
    "    if not os.path.exists(outfiledir):\n",
    "        os.makedirs(outfiledir)\n",
    "\n",
    "    with open(outfilepath, \"w\") as f:\n",
    "        json.dump(jsondic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\\\n",
    ".sort_values([\"trafficType\", \"accessType\", \"domain\", \"year\", \"month\", \"day\", \"hour\", \"y\"], ascending=[False, False, False, True, True, True, True, False])\\\n",
    ".groupby([\"trafficType\", \"accessType\", \"domain\", \"year\", \"month\", \"day\"])\\\n",
    ".apply(df_to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputdir = \"../../data/website/hourly\"\n",
    "\n",
    "# problematicpaths = []\n",
    "\n",
    "# prefilter_df = df\n",
    "# for tt in [\"spider\"]:#[\"user\", \"spider\"]:\n",
    "#     # prefilter_df = prefilter_df[(df[\"trafficType\"] == tt)]\n",
    "#     for at in [\"mobile-web\"]:#[\"desktop\", \"mobile-dev\", \"mobile-app\"]:\n",
    "#         # prefilter_df = prefilter_df[(df[\"accessType\"] == at)]\n",
    "#         for domain in [\"en.wikipedia\", \"de.wikipedia\", \"fr.wikipedia\", \"es.wikipedia\", \"ru.wikipedia\", \"zh.wikipedia\"]:\n",
    "#             # prefilter_df = prefilter_df[(df[\"domain\"] == domain)]\n",
    "#             for year in [2019]:\n",
    "#                 # prefilter_df = prefilter_df[(df[\"date\"].dt.year == year)]\n",
    "#                 for month in [9]:\n",
    "#                     # prefilter_df = prefilter_df[(df[\"date\"].dt.month == month)]\n",
    "#                     for day in range(1,32):\n",
    "#                         # prefilter_df = prefilter_df[(df[\"date\"].dt.day == day)]\n",
    "\n",
    "#                         jsondic = {i:[] for i in range(24)}\n",
    "\n",
    "#                         # print(1)\n",
    "#                         # for hour in range(24):\n",
    "\n",
    "#                         #     # print(1)\n",
    "#                         #     filtered_df = prefilter_df[\n",
    "#                         #         (df[\"date\"].dt.hour == hour)\n",
    "#                         #     ]\n",
    "\n",
    "#                         #     # filtered_df.sort_values(\"y\", ascending=False, inplace=True)\n",
    "\n",
    "#                         #     # print(2)\n",
    "#                         #     cumx = 0\n",
    "#                         #     for _, (x, y) in filtered_df[[\"x\", \"y\"]].iterrows():\n",
    "#                         #         cumx += x\n",
    "#                         #         jsondic[hour].append({\"x\":int(cumx), \"y\":int(y)})\n",
    "\n",
    "#                         # print(3)\n",
    "#                         outfilepath = f\"./{outputdir}/{tt}/{at}/{domain}/{year}-{month:02d}-{day:02d}.json\"\n",
    "#                         outfiledir = \"/\".join(outfilepath.split(\"/\")[:-1])\n",
    "\n",
    "#                         # print(4)\n",
    "#                         if not os.path.exists(outfiledir):\n",
    "#                             os.makedirs(outfiledir)\n",
    "\n",
    "#                     #     print(5)\n",
    "#                         with open(outfilepath, \"w\") as f:\n",
    "#                             json.dump(jsondic, f)\n",
    "\n",
    "#                     # 8/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mdbfs:/mnt/group09/websitedatamonthly/oct2019.parquet/_SUCCESS\u001b[0m -> ../../data/website/databricks/monthly/oct2019.parquet/_SUCCESS\n",
      "\u001b[4mdbfs:/mnt/group09/websitedatamonthly/oct2019.parquet/_committed_3991830075715639578\u001b[0m -> ../../data/website/databricks/monthly/oct2019.parquet/_committed_3991830075715639578\n",
      "\u001b[4mdbfs:/mnt/group09/websitedatamonthly/oct2019.parquet/_started_3991830075715639578\u001b[0m -> ../../data/website/databricks/monthly/oct2019.parquet/_started_3991830075715639578\n",
      "\u001b[4mdbfs:/mnt/group09/websitedatamonthly/oct2019.parquet/part-00000-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078931-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/monthly/oct2019.parquet/part-00000-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078931-1.c000.snappy.parquet\n",
      "\u001b[4mdbfs:/mnt/group09/websitedatamonthly/oct2019.parquet/part-00001-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078933-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/monthly/oct2019.parquet/part-00001-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078933-1.c000.snappy.parquet\n",
      "\u001b[4mdbfs:/mnt/group09/websitedatamonthly/oct2019.parquet/part-00002-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078955-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/monthly/oct2019.parquet/part-00002-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078955-1.c000.snappy.parquet\n",
      "\u001b[4mdbfs:/mnt/group09/websitedatamonthly/oct2019.parquet/part-00003-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078963-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/monthly/oct2019.parquet/part-00003-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078963-1.c000.snappy.parquet\n",
      "\u001b[4mdbfs:/mnt/group09/websitedatamonthly/oct2019.parquet/part-00004-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078972-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/monthly/oct2019.parquet/part-00004-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078972-1.c000.snappy.parquet\n",
      "\u001b[4mdbfs:/mnt/group09/websitedatamonthly/oct2019.parquet/part-00005-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078984-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/monthly/oct2019.parquet/part-00005-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078984-1.c000.snappy.parquet\n",
      "\u001b[4mdbfs:/mnt/group09/websitedatamonthly/oct2019.parquet/part-00006-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078993-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/monthly/oct2019.parquet/part-00006-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3078993-1.c000.snappy.parquet\n",
      "\u001b[4mdbfs:/mnt/group09/websitedatamonthly/oct2019.parquet/part-00007-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3079001-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/monthly/oct2019.parquet/part-00007-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3079001-1.c000.snappy.parquet\n",
      "\u001b[4mdbfs:/mnt/group09/websitedatamonthly/oct2019.parquet/part-00008-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3079010-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/monthly/oct2019.parquet/part-00008-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3079010-1.c000.snappy.parquet\n",
      "\u001b[4mdbfs:/mnt/group09/websitedatamonthly/oct2019.parquet/part-00009-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3079014-1.c000.snappy.parquet\u001b[0m -> ../../data/website/databricks/monthly/oct2019.parquet/part-00009-tid-3991830075715639578-6cb3ee07-9699-4a90-896d-3da10f0e6309-3079014-1.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "# !dbfs cp -r \"dbfs:/mnt/group09/websitedatamonthly/sep2018.parquet\" \"../../data/website/databricks/monthly/sep2018.parquet\"\n",
    "# !dbfs cp -r \"dbfs:/mnt/group09/websitedatamonthly/sep2019.parquet\" \"../../data/website/databricks/monthly/sep2019.parquet\"\n",
    "!dbfs cp -r \"dbfs:/mnt/group09/websitedatamonthly/oct2019.parquet\" \"../../data/website/databricks/monthly/oct2019.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>domain</th>\n",
       "      <th>trafficType</th>\n",
       "      <th>accessType</th>\n",
       "      <th>sumcount</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1570557600</td>\n",
       "      <td>es.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>mobile-web</td>\n",
       "      <td>34494</td>\n",
       "      <td>2019-10-08 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1570471200</td>\n",
       "      <td>de.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>mobile-app</td>\n",
       "      <td>75817</td>\n",
       "      <td>2019-10-07 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1570597200</td>\n",
       "      <td>es.wikipedia</td>\n",
       "      <td>spider</td>\n",
       "      <td>desktop</td>\n",
       "      <td>3096</td>\n",
       "      <td>2019-10-09 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1570028400</td>\n",
       "      <td>de.wikipedia</td>\n",
       "      <td>spider</td>\n",
       "      <td>desktop</td>\n",
       "      <td>31569</td>\n",
       "      <td>2019-10-02 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1570489200</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>mobile-app</td>\n",
       "      <td>98549</td>\n",
       "      <td>2019-10-07 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>1570143600</td>\n",
       "      <td>es.wikipedia</td>\n",
       "      <td>spider</td>\n",
       "      <td>desktop</td>\n",
       "      <td>10873</td>\n",
       "      <td>2019-10-03 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>1570168800</td>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>spider</td>\n",
       "      <td>desktop</td>\n",
       "      <td>314435</td>\n",
       "      <td>2019-10-04 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>1570575600</td>\n",
       "      <td>fr.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>mobile-app</td>\n",
       "      <td>5977</td>\n",
       "      <td>2019-10-08 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>1570392000</td>\n",
       "      <td>ru.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>mobile-web</td>\n",
       "      <td>6624</td>\n",
       "      <td>2019-10-06 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>1570071600</td>\n",
       "      <td>ru.wikipedia</td>\n",
       "      <td>user</td>\n",
       "      <td>mobile-web</td>\n",
       "      <td>3578</td>\n",
       "      <td>2019-10-03 03:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8640 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp        domain trafficType  accessType  sumcount  \\\n",
       "0     1570557600  es.wikipedia        user  mobile-web     34494   \n",
       "1     1570471200  de.wikipedia        user  mobile-app     75817   \n",
       "2     1570597200  es.wikipedia      spider     desktop      3096   \n",
       "3     1570028400  de.wikipedia      spider     desktop     31569   \n",
       "4     1570489200  en.wikipedia        user  mobile-app     98549   \n",
       "...          ...           ...         ...         ...       ...   \n",
       "8635  1570143600  es.wikipedia      spider     desktop     10873   \n",
       "8636  1570168800  en.wikipedia      spider     desktop    314435   \n",
       "8637  1570575600  fr.wikipedia        user  mobile-app      5977   \n",
       "8638  1570392000  ru.wikipedia        user  mobile-web      6624   \n",
       "8639  1570071600  ru.wikipedia        user  mobile-web      3578   \n",
       "\n",
       "                    date  \n",
       "0    2019-10-08 18:00:00  \n",
       "1    2019-10-07 18:00:00  \n",
       "2    2019-10-09 05:00:00  \n",
       "3    2019-10-02 15:00:00  \n",
       "4    2019-10-07 23:00:00  \n",
       "...                  ...  \n",
       "8635 2019-10-03 23:00:00  \n",
       "8636 2019-10-04 06:00:00  \n",
       "8637 2019-10-08 23:00:00  \n",
       "8638 2019-10-06 20:00:00  \n",
       "8639 2019-10-03 03:00:00  \n",
       "\n",
       "[8640 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../../data/website/databricks/monthly/oct2019.parquet\").drop_duplicates()\n",
    "df[\"date\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir = \"../../data/website/monthly\"\n",
    "\n",
    "problematicpaths = []\n",
    "\n",
    "for tt in [\"user\", \"spider\"]:\n",
    "    for at in [\"desktop\", \"mobile-web\", \"mobile-app\"]:\n",
    "        for domain in [\"en.wikipedia\", \"de.wikipedia\", \"fr.wikipedia\", \"es.wikipedia\", \"ru.wikipedia\", \"zh.wikipedia\"]:\n",
    "            for year in [2019]:\n",
    "                for month in [10]:\n",
    "\n",
    "                    jsondic = []\n",
    "\n",
    "                    filtered_df = df[\n",
    "                        (df[\"domain\"] == domain) &\n",
    "                        (df[\"accessType\"] == at) &\n",
    "                        (df[\"trafficType\"] == tt) &\n",
    "                        (df[\"date\"].dt.year == year) &\n",
    "                        (df[\"date\"].dt.month == month)\n",
    "                    ]\n",
    "\n",
    "                    filtered_df.sort_values(\"timestamp\", ascending=True, inplace=True)\n",
    "\n",
    "                    for _, (date, y) in filtered_df[[\"date\", \"sumcount\"]].iterrows():\n",
    "                        x = f\"{date.year:04d}-{date.month:02d}-{date.day:02d}-{date.hour:02d}\"\n",
    "                        jsondic.append({\"x\":x, \"y\":int(y)})\n",
    "\n",
    "                    outfilepath = f\"./{outputdir}/{tt}/{at}/{domain}/{year}-{month:02d}.json\"\n",
    "                    outfiledir = \"/\".join(outfilepath.split(\"/\")[:-1])  # the directory where the file is in\n",
    "\n",
    "                    if not os.path.exists(outfiledir):\n",
    "                        os.makedirs(outfiledir)\n",
    "\n",
    "                    with open(outfilepath, \"w\") as f:\n",
    "                        json.dump(jsondic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: ../../data/website/hourly/*/*/*/2020-*.json\n"
     ]
    }
   ],
   "source": [
    "# !rm ../../data/website/hourly/*/*/*/2020-*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
