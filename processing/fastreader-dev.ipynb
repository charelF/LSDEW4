{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "bigfilepath = \"../data/pageviews-20210101-automated\"\n",
    "smallfilepath = \"../exploration/sample.txt\"\n",
    "outputfilepath = \"../data/output_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:00, 10081.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en.charel', 'TEST_9999countAtTime0,1countAtTime1,2countAtTime3,', '1234', 'mobile', '123', 'A9999B1C2\\n']\n",
      "['en.wikipedia', 'Ä€nanda', '1735', 'desktop', '3', 'P1V1W1\\n']\n",
      "['en.wikipedia', 'Å kovec,_Trebnje', '30815184', 'desktop', '1', 'I1\\n']\n",
      "['en.wikipedia', 'ÌŒ', '236552', 'desktop', '3', 'E1F1G1\\n']\n",
      "['en.wikipedia', 'à¹ˆ', '63731', 'desktop', '1', 'F1\\n']\n",
      "['en.wikipedia', 'âˆ¿', '324749', 'desktop', '3', 'F1M1X1\\n']\n",
      "['en.wikipedia', 'ðŸ¦¥', '5168174', 'desktop', '2', 'F1S1\\n']\n",
      "['en.wikipedia', '-', '1066347', 'desktop', '2', 'O1P1\\n']\n",
      "['en.wikipedia', '-', '111765', 'desktop', '1', 'T1\\n']\n",
      "['es.charel', '1234', 'abcd', 'desktop', '1', 'T1\\n']\n",
      "here1\n",
      "here2\n",
      "['ar.wikipedia', 'ØµØ§Ø±ÙˆØ®_Ø¨Ø§Ù„ÙŠØ³ØªÙŠ_Ø¹Ø§Ø¨Ø±_Ù„Ù„Ù‚Ø§Ø±Ø§Øª', '240808', 'desktop', '1', 'F1\\n']\n",
      "['ar.wikipedia', 'Ø¹ØµÙˆØ±_ÙˆØ³Ø·Ù‰_Ù…ØªÙˆØ³Ø·Ø©', '471789', 'desktop', '1', 'P1Q1\\n']\n",
      "['en.wikipedia', 'Talk:H:IPA', 'null', 'desktop', '2', 'J2\\n']\n",
      "['fi.wikipedia', '1738', '2250', 'desktop', '1', 'S1\\n']\n",
      "['hi.wikipedia', 'à¤®à¤²à¤¾à¤¨à¤¾_à¤¹à¤¿à¤²à¥à¤¸_à¤¹à¤¿à¤®à¤¾à¤šà¤²', '1186807', 'desktop', '1', 'S1\\n']\n",
      "['zh.wikisource', 'ç¬¬å…­å±Šå…¨å›½äººæ°‘ä»£è¡¨å¤§ä¼šç¬¬ä¸‰æ¬¡ä¼šè®®å…³äºŽæ‰¹å‡†ã€Šä¸­åŽäººæ°‘å…±å’Œå›½æ”¿åºœå’Œå¤§ä¸åˆ—é¢ åŠåŒ—çˆ±å°”å…°è”åˆçŽ‹å›½æ”¿åºœå…³äºŽé¦™æ¸¯é—®é¢˜çš„è”åˆå£°æ˜Žã€‹çš„å†³å®š', '650212', 'desktop', '2', 'W2\\n']\n",
      "['als.wikipedia', '808', '64376', 'desktop', '1', 'P1\\n']\n",
      "['als.wikipedia', 'Ada_Lovelace', '51323', 'mobile-web', '1', 'P1\\n']\n",
      "['th.wikipedia', '23_à¸ªà¸´à¸‡à¸«à¸²à¸„à¸¡', '12013', 'desktop', '1', 'H1\\n']\n",
      "['jv.wikipedia', '26_Juni', '2278', 'desktop', '1', 'F1\\n']\n",
      "['ja.wikipedia', '10ã‚®ã‚¬ãƒ“ãƒƒãƒˆãƒ»ã‚¤ãƒ¼ã‚µãƒãƒƒãƒˆ', '1194926', 'desktop', '4', 'D2F1I1\\n']\n",
      "['ja.wikipedia', '185', '589222', 'desktop', '1', 'F1\\n']\n",
      "['en.wikipedia', 'BÌ¤Ä“', '4889214', 'desktop', '6', 'F5I1\\n']\n",
      "['en.wikipedia', '0-3-0', '14287894', 'desktop', '1', 'C1\\n']\n",
      "['en.wikipedia', '10.9', '31104124', 'mobile-web', '1', 'X1\\n']\n",
      "['ar.wikipedia', 'Ø§Ù„Ø£Ø«Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ_Ù„Ø¬Ø§Ø¦Ø­Ø©_ÙÙŠØ±ÙˆØ³_ÙƒÙˆØ±ÙˆÙ†Ø§_2019â€“20', '7429096', 'mobile-web', '1', 'N1\\n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outstring = \"\"\n",
    "outlist = []\n",
    "max_iterations = 10 * 1000 * 1000\n",
    "\n",
    "code_to_hour_dic = {letter:str(num) for num,letter in enumerate(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")}\n",
    "\n",
    "with open(smallfilepath) as infile:\n",
    "    for i, line in tqdm(enumerate(infile)):\n",
    "        # split line into list of words\n",
    "        wordlist = line.split(\" \")\n",
    "\n",
    "        if len(wordlist) == 6:\n",
    "            # the case where we have an ID\n",
    "            # print(wordlist[2], wordlist[2].isnumeric(), wordlist[2] == \"null\")\n",
    "            print(wordlist)\n",
    "            if wordlist[2].isnumeric() or (wordlist[2] == \"null\"):\n",
    "                # the case where a numeric value (or null) is at third position\n",
    "                # so:\n",
    "                    # title: abcd, id:1234\n",
    "                    # title: abcd, id:null\n",
    "                    # title: 1234, id:1234\n",
    "                    # title: 1234, id:null\n",
    "                pass\n",
    "            else:\n",
    "                # case where there is a word at third position that is neither numeric nor null\n",
    "                # so:\n",
    "                    # title: 1234, id:abcd --> swap\n",
    "                    # title: abcd, id:abcd --> ???\n",
    "                    # title: null, id:abcd --> swap\n",
    "                # we swap, if the value at 2nd position is either null or numeric\n",
    "                print(\"here1\")\n",
    "                if wordlist[1].isnumeric() or (wordlist[1] == \"null\"):\n",
    "                    print(\"here2\")\n",
    "                    wordlist[1], wordlist[2] = wordlist[2], wordlist[1]\n",
    "        else:\n",
    "            # the case where we do not have an ID\n",
    "            wordlist.insert(2, \"null\")\n",
    "        # at this point there is for sure* an id or null at position 3\n",
    "        # *unless there is an entry that has 6 rows with pos 2 and 3 both non-null words\n",
    "        if wordlist[2] == \"null\":\n",
    "            wordlist[2] = \"-1\"\n",
    "\n",
    "        # now we divide to days\n",
    "        wordlists = []\n",
    "\n",
    "        # divide last string into separate entries\n",
    "        count = \"\"\n",
    "        time = \"\"\n",
    "        first = True\n",
    "        for symbol in wordlist[-1]:\n",
    "            if symbol.isalpha():\n",
    "                if not first:\n",
    "                    # if this is not the first iteration, count is a valid number and time has also been set\n",
    "                    # since its not the first, we just encountered a letter again, hence we write to the wordlists\n",
    "                    # we write the original list, without the A1B2C3 string and instead encoding the first pair A1 to time: 0, count: 1\n",
    "                    wordlists.append(wordlist[:-1] + [time, count])\n",
    "                    count = \"\"\n",
    "                else: first = False  # if it was the first, the next one wont be the first\n",
    "                # in any case we get the time                    \n",
    "                time = code_to_hour_dic[symbol]\n",
    "            elif symbol.isnumeric():\n",
    "                count += symbol\n",
    "            elif symbol == \"\\n\":\n",
    "                # we arrived at the end\n",
    "                wordlists.append(wordlist[:-1] + [time, count])\n",
    "                break\n",
    "        # now we have a wordlists which contains the counts split by hour\n",
    "\n",
    "        # recombine cleaned list of words into line\n",
    "        # for wordlist in wordlists:\n",
    "        #     outstring += \" \".join(wordlist) + \"\\n\"\n",
    "        #     outlist.append(wordlist)\n",
    "        outlist += wordlists\n",
    "        if i > max_iterations:\n",
    "            break\n",
    "\n",
    "# with open(outputfilepath, \"w\") as outfile:\n",
    "#     outfile.write(outstring)\n",
    "\n",
    "outstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar.wikipedia Ø§Ù„Ø£Ø«Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ_Ù„Ø¬Ø§Ø¦Ø­Ø©_ÙÙŠØ±ÙˆØ³_ÙƒÙˆØ±ÙˆÙ†Ø§_2019â€“20 7429096 mobile-web 1 N1\n",
      "b'ar.wikipedia \\\\u0627\\\\u0644\\\\u0623\\\\u062b\\\\u0631_\\\\u0627\\\\u0644\\\\u0627\\\\u0642\\\\u062a\\\\u0635\\\\u0627\\\\u062f\\\\u064a_\\\\u0644\\\\u062c\\\\u0627\\\\u0626\\\\u062d\\\\u0629_\\\\u0641\\\\u064a\\\\u0631\\\\u0648\\\\u0633_\\\\u0643\\\\u0648\\\\u0631\\\\u0648\\\\u0646\\\\u0627_2019\\\\u201320 7429096 mobile-web 1 N1'\n"
     ]
    }
   ],
   "source": [
    "# a = ['ar.wikipedia', 'ØµØ§Ø±ÙˆØ®_Ø¨Ø§Ù„ÙŠØ³ØªÙŠ_Ø¹Ø§Ø¨Ø±_Ù„Ù„Ù‚Ø§Ø±Ø§Øª' , '240808', 'desktop', '1', 'F1\\n']\n",
    "# a = ['fi.wikipedia', '1738', '2250', 'desktop', '1', 'S1\\n']\n",
    "b = \"ar.wikipedia Ø§Ù„Ø£Ø«Ø±_Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ_Ù„Ø¬Ø§Ø¦Ø­Ø©_ÙÙŠØ±ÙˆØ³_ÙƒÙˆØ±ÙˆÙ†Ø§_2019â€“20 7429096 mobile-web 1 N1\"\n",
    "rtl = \"\\u200f\"\n",
    "ltr = \"\\u200e\"\n",
    "\n",
    "print(b)\n",
    "\n",
    "# b = b.encode('ascii', 'backslashreplace')\n",
    "# print(b)\n",
    "# for i,s in enumerate(b):\n",
    "#     if s == rtl:\n",
    "#         print(\"XXX\")\n",
    "#     if s == ltr:\n",
    "#         print(\"YYY\")\n",
    "#     print(s, end=\"_\")\n",
    "\n",
    "# print(b.encode('ascii', 'ignore'))\n",
    "print(b.encode('ascii', 'backslashreplace'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines read: 1M\n",
      "lines read: 2M\n",
      "lines read: 3M\n",
      "lines read: 4M\n",
      "lines read: 5M\n",
      "lines read: 6M\n",
      "lines read: 7M\n",
      "lines read: 8M\n",
      "lines read: 9M\n",
      "lines read: 10M\n"
     ]
    }
   ],
   "source": [
    "maxlines = 10 * 1000 * 1000\n",
    "import bz2\n",
    "with bz2.open(\"../data/pageviews-20190901-spider.bz2\", mode=\"rt\") as infile:\n",
    "# with open(\"../data/pageviews-20180131-user\") as infile:\n",
    "    for i, line in enumerate(infile):\n",
    "\n",
    "        if (i > maxlines):  # early stop\n",
    "            break\n",
    "        if (i > 0) and ((i % 1000000) == 0):  # progress\n",
    "            print(f\"lines read: {i//1000000}M\")\n",
    "\n",
    "        # if i < 10000000: continue\n",
    "\n",
    "        # split line into list of words\n",
    "        wordlist = line.split(\" \")\n",
    "        if (len(wordlist) != 5) and (len(wordlist) != 6):\n",
    "            # the case where we do not have an ID\n",
    "            # wordlist.insert(2, \"null\")\n",
    "            print(line, end=f\"{[i]}\")\n",
    "            # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"../data/findpdf3\" | grep -P \"^[a-z]{2,3}\\.[^ ]*wik[^ ]* [^ ]+ [0-9]* (mobile-web|mobile-app|desktop) [0-9]+ ([A-Z][0-9]+)+$\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"../data/pageviews-20180131-user\" | grep -P --text -v \"^[^ ]+ [^ ]+ ([0-9]* )?(mobile-web|mobile-app|desktop) [0-9]+ ([A-Z][0-9]+)+$\" > ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediawiki\n",
    "bat-ent"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
